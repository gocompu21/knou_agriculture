"""
ë„¤ì´ë²„ ì¹´í˜ ê¸€ ê°€ì ¸ì˜¤ê¸° (ë‹¤ìŒê¸€ ë°˜ë³µ ì½ê¸°)
- ì…€ë ˆë‹ˆì›€ìœ¼ë¡œ ë„¤ì´ë²„ ë¡œê·¸ì¸ (pyperclip ë°©ì‹)
- ì¹´í˜ ê¸€ ë‚´ìš© ìŠ¤í¬ë˜í•‘
- 'ê¸°ë§ì‹œí—˜ í›„ê¸°' ê²Œì‹œíŒì˜ ë‹¤ìŒê¸€ì„ ë°˜ë³µì ìœ¼ë¡œ ì½ê¸°
"""

import os
import time
import pyperclip
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager


# â”€â”€ ë„¤ì´ë²„ ê³„ì • ì •ë³´ â”€â”€
NAVER_ID = "compu21"
NAVER_PW = "nipdms55"

# â”€â”€ ë„¤ì´ë²„ ë¡œê·¸ì¸ URL â”€â”€
LOGIN_URL = "https://nid.naver.com/nidlogin.login"

# â”€â”€ ì¹´í˜ ê¸€ URL (ì‹œì‘ì ) â”€â”€
CAFE_ARTICLE_URL = (
    "https://cafe.naver.com/f-e/cafes/30428231/articles/11217"
    "?boardtype=L&menuid=137&referrerAllArticles=false"
)

# â”€â”€ ìµœëŒ€ ì½ì„ ê¸€ ìˆ˜ (9999 = ì‚¬ì‹¤ìƒ ë¬´ì œí•œ, ë‹¤ìŒê¸€ì´ ì—†ì„ ë•Œ ìë™ ì¢…ë£Œ) â”€â”€
MAX_ARTICLES = 9999

# â”€â”€ ê²°ê³¼ ì €ì¥ ê²½ë¡œ â”€â”€
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_FILE = os.path.join(BASE_DIR, "ì¹´í˜ê¸€_ê²°ê³¼.txt")
DEBUG_HTML_FILE = os.path.join(BASE_DIR, "temp_cafe_page.html")


def create_driver():
    """í¬ë¡¬ ë“œë¼ì´ë²„ ìƒì„±"""
    chrome_options = Options()
    # ìë™í™” íƒì§€ ìš°íšŒ ì˜µì…˜
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation", "enable-logging"])
    chrome_options.add_experimental_option("useAutomationExtension", False)
    # ë¡œê·¸ ë ˆë²¨ ì„¤ì •
    chrome_options.add_argument("--log-level=3")
    # User-Agent ì„¤ì •
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/144.0.0.0 Safari/537.36"
    )
    # ì°½ í¬ê¸° ì„¤ì •
    chrome_options.add_argument("--window-size=1280,900")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)

    # navigator.webdriver ì†ì„± ì œê±° (ë´‡ íƒì§€ ìš°íšŒ)
    driver.execute_cdp_cmd(
        "Page.addScriptToEvaluateOnNewDocument",
        {"source": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"},
    )

    return driver


def pyperclip_input(element, text):
    """
    pyperclipì„ ì´ìš©í•œ ì…ë ¥ ë°©ì‹
    - ì§ì ‘ íƒ€ì´í•‘ ëŒ€ì‹  í´ë¦½ë³´ë“œ ë³µì‚¬ â†’ ë¶™ì—¬ë„£ê¸°ë¡œ ì…ë ¥
    - ë„¤ì´ë²„ ë´‡ íƒì§€(í‚¤ ì…ë ¥ íŒ¨í„´ ë¶„ì„) ìš°íšŒìš©
    """
    element.click()
    time.sleep(0.3)
    element.clear()
    time.sleep(0.2)

    # pyperclipìœ¼ë¡œ í´ë¦½ë³´ë“œì— ë³µì‚¬
    pyperclip.copy(text)
    time.sleep(0.2)

    # Ctrl+Vë¡œ ë¶™ì—¬ë„£ê¸°
    element.send_keys(Keys.CONTROL, "v")
    time.sleep(0.5)


def naver_login(driver):
    """ë„¤ì´ë²„ ë¡œê·¸ì¸ ìˆ˜í–‰"""
    print("ğŸ” ë„¤ì´ë²„ ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì† ì¤‘...")
    driver.get(LOGIN_URL)
    time.sleep(3)

    wait = WebDriverWait(driver, 10)

    # â”€â”€ 1) ì•„ì´ë”” ì…ë ¥ (id="id") â”€â”€
    print("ğŸ“ ì•„ì´ë”” ì…ë ¥ ì¤‘...")
    id_input = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "input#id")))
    pyperclip_input(id_input, NAVER_ID)
    time.sleep(1)

    # â”€â”€ 2) ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ (id="pw") â”€â”€
    print("ğŸ”‘ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ ì¤‘...")
    pw_input = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "input#pw")))
    pyperclip_input(pw_input, NAVER_PW)
    time.sleep(1)

    # â”€â”€ 3) ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­ (id="log.login") â”€â”€
    print("ğŸ–±ï¸ ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­...")
    login_btn = wait.until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, "button#log\\.login"))
    )
    login_btn.click()
    print("â³ ë¡œê·¸ì¸ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘...")
    time.sleep(5)

    # â”€â”€ 4) ë¡œê·¸ì¸ ê²°ê³¼ í™•ì¸ â”€â”€
    current_url = driver.current_url
    print(f"ğŸ“ í˜„ì¬ URL: {current_url}")

    # 'ìƒˆë¡œìš´ ê¸°ê¸° ë“±ë¡' ë“±ì˜ ì¶”ê°€ ì¸ì¦ í˜ì´ì§€ê°€ ëœ° ìˆ˜ ìˆìŒ
    if "nid.naver.com" in current_url:
        print("âš ï¸  ì¶”ê°€ ì¸ì¦ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        print("   (60ì´ˆ ëŒ€ê¸° ì¤‘... ì¸ì¦ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤)")
        for i in range(60):
            time.sleep(1)
            if "nidlogin" not in driver.current_url:
                break

    # ë¡œê·¸ì¸ ì„±ê³µ ì—¬ë¶€ í™•ì¸
    if "nidlogin" not in driver.current_url:
        print("âœ… ë„¤ì´ë²„ ë¡œê·¸ì¸ ì„±ê³µ!")
        return True
    else:
        print("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨ ë˜ëŠ” ì¶”ê°€ ì¸ì¦ í•„ìš”")
        return False


def read_cafe_article(driver, url):
    """
    ë„¤ì´ë²„ ì¹´í˜ ê¸€ ë‚´ìš© ì½ê¸°
    - ë„¤ì´ë²„ ì¹´í˜ëŠ” iframe(#cafe_main) ì•ˆì— ë³¸ë¬¸ì´ ë Œë”ë§ë¨
    - iframeìœ¼ë¡œ ì „í™˜ í›„ ë³¸ë¬¸ ì¶”ì¶œ
    """
    print(f"\nğŸ“– ì¹´í˜ ê¸€ ì ‘ì† ì¤‘...")
    print(f"   URL: {url}")
    driver.get(url)

    # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
    print("â³ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘ (5ì´ˆ)...")
    time.sleep(5)

    wait = WebDriverWait(driver, 15)

    result = {
        "title": "",
        "author": "",
        "date": "",
        "content": "",
        "comments": [],
        "url": url,
    }

    try:
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # iframe(cafe_main)ìœ¼ë¡œ ì „í™˜
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        print("ğŸ”„ iframe(cafe_main)ìœ¼ë¡œ ì „í™˜ ì¤‘...")
        iframe = wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "iframe#cafe_main"))
        )
        driver.switch_to.frame(iframe)
        print("âœ… iframe ì „í™˜ ì™„ë£Œ!")
        time.sleep(3)

        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # ê¸€ ì œëª© ì°¾ê¸°
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        title_selectors = [
            "h3.title_text",
            ".article_header .title_text",
            ".tit_area .title_text",
            ".ArticleTitle .title_text",
            ".se_title .se_textarea",
            "h3[class*='title']",
        ]
        for sel in title_selectors:
            try:
                el = driver.find_element(By.CSS_SELECTOR, sel)
                text = el.text.strip()
                if text and len(text) > 0:
                    result["title"] = text
                    print(f"ğŸ“Œ ì œëª©: {result['title']}")
                    break
            except Exception:
                continue

        if not result["title"]:
            try:
                title_tag = driver.title
                if title_tag:
                    result["title"] = title_tag.replace(" : ë„¤ì´ë²„ ì¹´í˜", "").strip()
                    print(f"ğŸ“Œ ì œëª© (title íƒœê·¸): {result['title']}")
            except Exception:
                print("âš ï¸  ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # ì‘ì„±ì ì°¾ê¸°
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        author_selectors = [
            ".nickname .text",
            ".profile_info .nickname",
            ".WriterInfo .nickname",
            ".article_writer .nick",
            ".nick_box .nickname",
            "[class*='nickname'] .text",
            ".se_author",
        ]
        for sel in author_selectors:
            try:
                el = driver.find_element(By.CSS_SELECTOR, sel)
                text = el.text.strip()
                if text and len(text) > 0:
                    result["author"] = text
                    print(f"ğŸ‘¤ ì‘ì„±ì: {result['author']}")
                    break
            except Exception:
                continue

        if not result["author"]:
            print("âš ï¸  ì‘ì„±ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # ì‘ì„± ë‚ ì§œ ì°¾ê¸°
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        date_selectors = [
            ".article_info .date",
            ".WriterInfo .date",
            ".profile_info .date",
            ".se_publishDate",
            "span.date",
        ]
        for sel in date_selectors:
            try:
                el = driver.find_element(By.CSS_SELECTOR, sel)
                text = el.text.strip()
                if text and len(text) > 3:
                    result["date"] = text
                    print(f"ğŸ“… ì‘ì„±ì¼: {result['date']}")
                    break
            except Exception:
                continue

        if not result["date"]:
            print("âš ï¸  ì‘ì„±ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # ë³¸ë¬¸ ë‚´ìš© ì°¾ê¸°
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        content_selectors = [
            ".se-main-container",
            ".article_viewer",
            "#body",
            ".ContentRenderer",
            ".content_area",
            ".ArticleContentBox",
            ".post_article",
        ]
        for sel in content_selectors:
            try:
                el = driver.find_element(By.CSS_SELECTOR, sel)
                text = el.text.strip()
                if text and len(text) > 10:
                    result["content"] = text
                    print(f"\nğŸ“„ ë³¸ë¬¸ ({len(text)}ì)")
                    break
            except Exception:
                continue

        if not result["content"]:
            print("âš ï¸  íŠ¹ì • ì…€ë ‰í„°ë¡œ ë³¸ë¬¸ì„ ì°¾ì§€ ëª»í•¨. body í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            try:
                body_text = driver.find_element(By.TAG_NAME, "body").text
                result["content"] = body_text
                print(f"ğŸ“„ iframe body í…ìŠ¤íŠ¸ ({len(body_text)}ì)")
            except Exception:
                print("âŒ í˜ì´ì§€ í…ìŠ¤íŠ¸ë„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # ëŒ“ê¸€ ì°¾ê¸°
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        comment_selectors = [
            ".comment_box .text_comment",
            ".comment_area .comment_box",
            ".CommentItem",
            "[class*='comment_text']",
        ]
        for sel in comment_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, sel)
                for el in elements:
                    text = el.text.strip()
                    if text:
                        result["comments"].append(text)
                if result["comments"]:
                    break
            except Exception:
                continue

        if result["comments"]:
            print(f"ğŸ’¬ ëŒ“ê¸€ {len(result['comments'])}ê°œ")

        # iframeì—ì„œ ë¹ ì ¸ë‚˜ì˜¤ê¸°
        driver.switch_to.default_content()

    except Exception as e:
        print(f"âŒ ê¸€ ì½ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        try:
            driver.switch_to.default_content()
        except Exception:
            pass

    return result


def find_next_article_url(driver):
    """
    í˜„ì¬ ê¸€ í˜ì´ì§€ì˜ iframe ì•ˆì—ì„œ 'ë‹¤ìŒê¸€' ë§í¬ë¥¼ ì°¾ì•„ URLì„ ë°˜í™˜
    - ë„¤ì´ë²„ ì¹´í˜ ê¸€ í•˜ë‹¨ì— 'ë‹¤ìŒê¸€' ë§í¬ê°€ ìˆìŒ
    - ê°™ì€ ê²Œì‹œíŒ(ê¸°ë§ì‹œí—˜ í›„ê¸°)ì˜ ë‹¤ìŒê¸€ë§Œ ëŒ€ìƒ
    - ë°˜í™˜ê°’: ë‹¤ìŒê¸€ URL (ì—†ìœ¼ë©´ None)
    """
    try:
        wait = WebDriverWait(driver, 10)

        # iframeìœ¼ë¡œ ì „í™˜
        iframe = wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "iframe#cafe_main"))
        )
        driver.switch_to.frame(iframe)
        time.sleep(2)

        next_url = None

        # â”€â”€ ë°©ë²• 1: ë‹¤ìŒê¸€ ë§í¬ ì°¾ê¸° (ë‹¤ì–‘í•œ ì…€ë ‰í„°) â”€â”€
        next_selectors = [
            # ë„¤ì´ë²„ ì¹´í˜ ì¼ë°˜ì ì¸ ë‹¤ìŒê¸€ ì˜ì—­
            ".ArticleNextArticle a",
            ".prev_next .next a",
            ".board_action .next a",
            ".Knext a",
            # 'ë‹¤ìŒê¸€' í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ëŠ” ë§í¬
            "a[class*='next']",
            "a[class*='Next']",
        ]

        for sel in next_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, sel)
                for el in elements:
                    href = el.get_attribute("href")
                    text = el.text.strip()
                    if href and ("articles" in href or "ArticleRead" in href):
                        next_url = href
                        print(f"ğŸ”— ë‹¤ìŒê¸€ ë°œê²¬: {text} â†’ {href}")
                        break
                if next_url:
                    break
            except Exception:
                continue

        # â”€â”€ ë°©ë²• 2: XPathë¡œ 'ë‹¤ìŒê¸€' í…ìŠ¤íŠ¸ ì£¼ë³€ ë§í¬ ì°¾ê¸° â”€â”€
        if not next_url:
            try:
                # "ë‹¤ìŒê¸€" í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ìš”ì†Œ ê·¼ì²˜ì˜ <a> íƒœê·¸
                next_elements = driver.find_elements(
                    By.XPATH,
                    "//*[contains(text(),'ë‹¤ìŒê¸€')]/ancestor::*[self::div or self::li or self::tr]//a[@href]"
                )
                for el in next_elements:
                    href = el.get_attribute("href")
                    text = el.text.strip()
                    if href and text and len(text) > 1:
                        # ì ˆëŒ€ URLë¡œ ë³€í™˜
                        if href.startswith("/"):
                            href = "https://cafe.naver.com" + href
                        next_url = href
                        print(f"ğŸ”— ë‹¤ìŒê¸€ ë°œê²¬ (XPath): {text}")
                        break
            except Exception:
                pass

        # â”€â”€ ë°©ë²• 3: 'ë‹¤ìŒê¸€' ë¼ë²¨ì´ ìˆëŠ” í–‰ì—ì„œ ë§í¬ ì¶”ì¶œ â”€â”€
        if not next_url:
            try:
                # ê¸€ í•˜ë‹¨ ë„¤ë¹„ê²Œì´ì…˜ì—ì„œ ë‹¤ìŒê¸€ ì°¾ê¸°
                all_links = driver.find_elements(By.CSS_SELECTOR, "a[href]")
                for link in all_links:
                    href = link.get_attribute("href") or ""
                    # ê°™ì€ ì¹´í˜ì˜ ë‹¤ë¥¸ ê¸€ ë§í¬ì¸ì§€ í™•ì¸
                    if "cafes/30428231/articles/" in href:
                        # í˜„ì¬ ê¸€ URLê³¼ ë‹¤ë¥¸ì§€ í™•ì¸
                        parent_text = ""
                        try:
                            parent = link.find_element(By.XPATH, "./..")
                            parent_text = parent.text.strip()
                        except Exception:
                            pass

                        if "ë‹¤ìŒê¸€" in parent_text or "ë‹¤ìŒ ê¸€" in parent_text:
                            next_url = href
                            link_text = link.text.strip()
                            print(f"ğŸ”— ë‹¤ìŒê¸€ ë°œê²¬ (ë¶€ëª¨ìš”ì†Œ): {link_text}")
                            break
            except Exception:
                pass

        # iframeì—ì„œ ë¹ ì ¸ë‚˜ì˜¤ê¸°
        driver.switch_to.default_content()

        return next_url

    except Exception as e:
        print(f"âš ï¸  ë‹¤ìŒê¸€ ì°¾ê¸° ì¤‘ ì˜¤ë¥˜: {e}")
        try:
            driver.switch_to.default_content()
        except Exception:
            pass
        return None



def save_result_append(result, article_num, is_first=False):
    """
    ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ì— ì¶”ê°€(append) ì €ì¥
    - is_first=True: íŒŒì¼ì„ ìƒˆë¡œ ìƒì„± (ì²« ë²ˆì§¸ ê¸€)
    - is_first=False: ê¸°ì¡´ íŒŒì¼ì— ì´ì–´ì„œ ì €ì¥
    """
    mode = "w" if is_first else "a"
    with open(OUTPUT_FILE, mode, encoding="utf-8") as f:
        if not is_first:
            f.write("\n\n")

        f.write(f"{'â”' * 70}\n")
        f.write(f"ğŸ“Œ [{article_num}ë²ˆì§¸ ê¸€]\n")
        f.write(f"{'â”' * 70}\n")
        f.write(f"ì œëª©: {result['title']}\n")
        f.write(f"ì‘ì„±ì: {result['author']}\n")
        f.write(f"ì‘ì„±ì¼: {result['date']}\n")
        f.write(f"URL: {result['url']}\n")
        f.write("=" * 60 + "\n")
        f.write(f"\n{result['content']}\n")
        f.write("\n" + "=" * 60 + "\n")
        if result["comments"]:
            f.write(f"\nëŒ“ê¸€ ({len(result['comments'])}ê°œ):\n")
            f.write("-" * 40 + "\n")
            for idx, comment in enumerate(result["comments"], 1):
                f.write(f"[{idx}] {comment}\n")

    print(f"ğŸ’¾ [{article_num}ë²ˆì§¸ ê¸€] ì €ì¥ ì™„ë£Œ")


import re


def get_resume_info():
    """
    ê¸°ì¡´ ê²°ê³¼ íŒŒì¼ì—ì„œ ë§ˆì§€ë§‰ ê¸€ ë²ˆí˜¸ì™€ URLì„ ì½ì–´ì™€ ì´ì–´ì„œ ì½ê¸° ì§€ì›
    ë°˜í™˜: (last_article_num, last_url) ë˜ëŠ” (0, None)
    """
    if not os.path.exists(OUTPUT_FILE):
        return 0, None

    last_num = 0
    last_url = None

    try:
        with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
            content = f.read()

        # [Në²ˆì§¸ ê¸€] íŒ¨í„´ì—ì„œ ê°€ì¥ ë§ˆì§€ë§‰ ë²ˆí˜¸ ì¶”ì¶œ
        nums = re.findall(r"\[(\d+)ë²ˆì§¸ ê¸€\]", content)
        if nums:
            last_num = int(nums[-1])

        # ë§ˆì§€ë§‰ URL: ì¤„ ì°¾ê¸°
        urls = re.findall(r"URL: (.+)", content)
        if urls:
            last_url = urls[-1].strip()

        if last_num > 0:
            print(f"ğŸ“‚ ê¸°ì¡´ íŒŒì¼ ë°œê²¬: {last_num}ê°œì˜ ê¸€ì´ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            print(f"   ë§ˆì§€ë§‰ ê¸€ URL: {last_url}")

    except Exception as e:
        print(f"âš ï¸  ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    return last_num, last_url


def main():
    """ë©”ì¸ ì‹¤í–‰ - ë‹¤ìŒê¸€ ë°˜ë³µ ì½ê¸° (ì´ì–´ì„œ ì½ê¸° ì§€ì›)"""
    driver = None
    try:
        # 0. ì´ì–´ì„œ ì½ê¸° í™•ì¸
        last_num, last_url = get_resume_info()

        resume_mode = False
        if last_num > 0 and last_url:
            print(f"\nâ“ ì´ì–´ì„œ ì½ì„ê¹Œìš”?")
            print(f"   [1] ì´ì–´ì„œ ì½ê¸° ({last_num}ë²ˆì§¸ ê¸€ ë‹¤ìŒë¶€í„°)")
            print(f"   [2] ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì½ê¸°")
            choice = input("   ì„ íƒ (1/2): ").strip()
            if choice == "1":
                resume_mode = True
                print(f"\nâ¡ï¸  {last_num}ë²ˆì§¸ ê¸€ ë‹¤ìŒë¶€í„° ì´ì–´ì„œ ì½ìŠµë‹ˆë‹¤.")
            else:
                print(f"\nğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì½ìŠµë‹ˆë‹¤.")

        # 1. ë“œë¼ì´ë²„ ìƒì„±
        driver = create_driver()
        print("ğŸš€ í¬ë¡¬ ë¸Œë¼ìš°ì € ì‹¤í–‰ ì™„ë£Œ")

        # 2. ë„¤ì´ë²„ ë¡œê·¸ì¸
        login_success = naver_login(driver)

        if login_success:
            print("\nâœ… ë¡œê·¸ì¸ ì™„ë£Œ! ì¹´í˜ ê¸€ ê°€ì ¸ì˜¤ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

            if resume_mode:
                # ì´ì–´ì„œ ì½ê¸°: ë§ˆì§€ë§‰ ê¸€ í˜ì´ì§€ë¡œ ì´ë™ â†’ ë‹¤ìŒê¸€ URL ê°€ì ¸ì˜¤ê¸°
                print(f"\nğŸ“– ë§ˆì§€ë§‰ ê¸€ í˜ì´ì§€ë¡œ ì´ë™í•˜ì—¬ ë‹¤ìŒê¸€ URLì„ ê°€ì ¸ì˜µë‹ˆë‹¤...")
                driver.get(last_url)
                time.sleep(5)
                next_url = find_next_article_url(driver)

                if next_url:
                    current_url = next_url
                    article_count = last_num
                    print(f"âœ… ë‹¤ìŒê¸€ ë°œê²¬! {article_count + 1}ë²ˆì§¸ ê¸€ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                else:
                    print("ğŸ ë§ˆì§€ë§‰ ê¸€ ì´í›„ ë‹¤ìŒê¸€ì´ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ì§‘ ì™„ë£Œ!")
                    input("ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤...")
                    return
            else:
                # ì²˜ìŒë¶€í„° ì½ê¸°
                current_url = CAFE_ARTICLE_URL
                article_count = 0

            visited_urls = set()  # ì¤‘ë³µ ë°©ë¬¸ ë°©ì§€

            while current_url and article_count < MAX_ARTICLES:
                # ì¤‘ë³µ ì²´í¬
                if current_url in visited_urls:
                    print(f"\nâš ï¸  ì´ë¯¸ ë°©ë¬¸í•œ ê¸€ì…ë‹ˆë‹¤. ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                    break
                visited_urls.add(current_url)

                article_count += 1
                print(f"\n{'=' * 70}")
                print(f"ğŸ“– [{article_count}ë²ˆì§¸ ê¸€] ì½ê¸° ì‹œì‘")
                print(f"{'=' * 70}")

                # 3. ì¹´í˜ ê¸€ ì½ê¸°
                article = read_cafe_article(driver, current_url)

                # 4. ê²°ê³¼ ì €ì¥ (ì´ì–´ì„œ ì½ê¸°ë©´ í•­ìƒ append)
                is_first = (article_count == 1 and not resume_mode)
                save_result_append(article, article_count, is_first)

                if article["title"]:
                    print(f"   ì œëª©: {article['title']}")
                    print(f"   ë³¸ë¬¸: {len(article['content'])}ì / ëŒ“ê¸€: {len(article['comments'])}ê°œ")
                else:
                    print("   âš ï¸ ê¸€ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                # 5. ë‹¤ìŒê¸€ URL ì°¾ê¸°
                print(f"\nğŸ” ë‹¤ìŒê¸€ ì°¾ëŠ” ì¤‘...")
                next_url = find_next_article_url(driver)

                if next_url:
                    print(f"â¡ï¸  ë‹¤ìŒê¸€ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                    current_url = next_url
                    # ë„¤ì´ë²„ ë´‡ íƒì§€ ë°©ì§€ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
                    time.sleep(3)
                else:
                    print(f"\nğŸ ë‹¤ìŒê¸€ì´ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ì§‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

            # â”€â”€ ìµœì¢… ê²°ê³¼ ìš”ì•½ â”€â”€
            print(f"\n{'=' * 70}")
            print(f"ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ!")
            print(f"   ì´ {article_count}ê°œì˜ ê¸€ì´ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            print(f"   ì €ì¥ íŒŒì¼: {OUTPUT_FILE}")
            print(f"{'=' * 70}")

            print("\nâ³ ë¸Œë¼ìš°ì €ë¥¼ í™•ì¸í•˜ì„¸ìš”. ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            input()
        else:
            print("\nâš ï¸  ë¡œê·¸ì¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê³„ì • ì •ë³´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            input("ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤...")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        input("ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤...")

    finally:
        if driver:
            driver.quit()
            print("ğŸ”’ ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")


if __name__ == "__main__":
    main()

